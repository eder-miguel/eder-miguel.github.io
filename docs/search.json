[
  {
    "objectID": "notes/ssh_config_file.html",
    "href": "notes/ssh_config_file.html",
    "title": "SSH configuration file",
    "section": "",
    "text": "To add a new connection to the SSH config file (~/.ssh/config), open it and write the following:\nHost [hostname_alias]\n  HostName [hostname]\n  User [username]\n  #PubKeyAuthentication yes # If accessing via SSH\n  #IdentityFile ~/.ssh/id_ed25519 # point to the private SSH key if available\n  #OTHER_SSH_OPTION value # General format of SSH options\nThen, from terminal, executing ssh [hostname_alias] will try to set a connection to the specified HostName using the specified User."
  },
  {
    "objectID": "notes/ssh_config_file.html#tldr",
    "href": "notes/ssh_config_file.html#tldr",
    "title": "SSH configuration file",
    "section": "",
    "text": "To add a new connection to the SSH config file (~/.ssh/config), open it and write the following:\nHost [hostname_alias]\n  HostName [hostname]\n  User [username]\n  #PubKeyAuthentication yes # If accessing via SSH\n  #IdentityFile ~/.ssh/id_ed25519 # point to the private SSH key if available\n  #OTHER_SSH_OPTION value # General format of SSH options\nThen, from terminal, executing ssh [hostname_alias] will try to set a connection to the specified HostName using the specified User."
  },
  {
    "objectID": "notes/ssh_config_file.html#breakdown",
    "href": "notes/ssh_config_file.html#breakdown",
    "title": "SSH configuration file",
    "section": "Breakdown",
    "text": "Breakdown\n\nEach section starting with Host defines a connection. The lines below this statement define properties of the specific connection.\n[hostname_alias] specifies an alias for the connection locally. Different aliases may specify the same HostName, e.g. to handle different users on a remote server.\nHostName [hostname] specifies the target hostname. It can be an IP address (86.87.88.89) or a text string (github.com). In the first case no domain resolution is necessary. In the second, the internal /etc/hosts file will be queried and if no match is found a DNS query will be performed.\nUser [username] indicates the username to use in that SSH connection. If not not defined, it defaults to the current username.\n\nA real example I use to connect to my home Raspberry Pi:\nHost raspberry\n  Hostname 192.168.X.Y\n  PubKeyAuthentication yes #\n  IdentityFile ~/.ssh/id_ed25519"
  },
  {
    "objectID": "notes/ssh_config_file.html#resources",
    "href": "notes/ssh_config_file.html#resources",
    "title": "SSH configuration file",
    "section": "Resources",
    "text": "Resources\n\nUseful summary of SSH config file format and options.\nStackoverflow thread on the interaction between /etc/hosts and ~/.ssh/config."
  },
  {
    "objectID": "notes/pytorch_gpu_memory_in_jupyter.html",
    "href": "notes/pytorch_gpu_memory_in_jupyter.html",
    "title": "Pytorch GPU memory management in Jupyter",
    "section": "",
    "text": "To clean-up cached memory in Pytorch:\ndel x\nwith torch.no_grad():\n    torch.cuda.empty_cache()\nNote that torch.cuda.empty_cache() simply frees cached memory. For this to be truly effective, we must carefully handle variables and contexts, like we do in the previous example deleting variable x.\nAlso, remember to the context manager when running the network in inference mode, e.g.:\nx, y = next(iter(dl))\nwith torch.no_grad():\n    pred = net(x)\nRunning the code above without the context manager may result in difficulties freeing up the GPU memory.\nTo check the global namespace in a Jupyter environment:\n%who\nwhich will return all variables living in the global namespace.\nA more advanced approach would involve checking the garbage collector for tracked variables and referrers:\nimport gc\nobjs_in_gpu = [obj for obj in gc.get_objects() if isinstance(obj, torch.Tensor) and obj.is_cuda]\nreferrers = gc.get_referrers(objs_in_gpu[0])"
  },
  {
    "objectID": "notes/pytorch_gpu_memory_in_jupyter.html#tldr",
    "href": "notes/pytorch_gpu_memory_in_jupyter.html#tldr",
    "title": "Pytorch GPU memory management in Jupyter",
    "section": "",
    "text": "To clean-up cached memory in Pytorch:\ndel x\nwith torch.no_grad():\n    torch.cuda.empty_cache()\nNote that torch.cuda.empty_cache() simply frees cached memory. For this to be truly effective, we must carefully handle variables and contexts, like we do in the previous example deleting variable x.\nAlso, remember to the context manager when running the network in inference mode, e.g.:\nx, y = next(iter(dl))\nwith torch.no_grad():\n    pred = net(x)\nRunning the code above without the context manager may result in difficulties freeing up the GPU memory.\nTo check the global namespace in a Jupyter environment:\n%who\nwhich will return all variables living in the global namespace.\nA more advanced approach would involve checking the garbage collector for tracked variables and referrers:\nimport gc\nobjs_in_gpu = [obj for obj in gc.get_objects() if isinstance(obj, torch.Tensor) and obj.is_cuda]\nreferrers = gc.get_referrers(objs_in_gpu[0])"
  },
  {
    "objectID": "notes/pytorch_gpu_memory_in_jupyter.html#breakdown",
    "href": "notes/pytorch_gpu_memory_in_jupyter.html#breakdown",
    "title": "Pytorch GPU memory management in Jupyter",
    "section": "Breakdown",
    "text": "Breakdown\n\nPython’s garbage collector is the mechanism used in Python to determine when a variable (and the corresponding memory) can be freed. A reference count mechanism is used to keep track of references to memory. Sometimes, reference count increases can go unnoticed and create issues since the garbage collector does not free the memory as expected.\nA common error is storing references to Pytorch-related variables attached to computation graphs (as described here). This will cause the computation graph to stay in memory and eventually trigger OOM errors or slow down processing due to inefficient memory management.\nA key pattern to avoid many of these errors is using context managers, which automatically handle reference counting and ensure that variables declared within the context are freed when the context is exited.\n\nwith torch.cuda.device(0):\n    # Code\n\nFunctions and exception blocks (try-except-finally) also serve this purpose and it is often a good idea to combine them in functions that perform heavy processing tasks which might be interrupted. Interruptions, if not handled properly, may also interfere with the reference counting mechanism. The following is a useful snippet\n\ndef func(params):\n    try:\n        # Heavy processing here\n    except: # Use specific exception if expected\n        torch.cuda.empty_cache() # Ensure cached memory is freed if exception triggers"
  },
  {
    "objectID": "notes/pytorch_gpu_memory_in_jupyter.html#resources",
    "href": "notes/pytorch_gpu_memory_in_jupyter.html#resources",
    "title": "Pytorch GPU memory management in Jupyter",
    "section": "Resources",
    "text": "Resources\n\nPost in iifx.dev discussing several methods to handle Out-Of-Memory errors associated to Pytorch.\nPost by Neerja Aggarwal describing OOM cases in the context of CUDA, Pytorch and Jupyter notebooks, and tips on avoiding them.\nOfficial Pytorch documentation on memory management when using CUDA.\nPost by Bartosz Mikulski discussing memory management in Jupyter notebooks.\nStackoverflow thread with additional discussions."
  },
  {
    "objectID": "notes/slurm_basic_commands.html",
    "href": "notes/slurm_basic_commands.html",
    "title": "SLURM basic commands",
    "section": "",
    "text": "Write the following SLURM directives and code in a file, e.g. job script.sh:\n#!/bin/bash\n\n#SBATCH --mail-type=ALL                # Type of events triggering email\n#SBATCH --mail-user=[email_address]    # Email address for notifications\n#SBATCH --job-name=[name_for_job]      # Job name\n#SBATCH --time=50:00:00                # Max. runtime, 50 hours in this case\n#SBATCH --mem=128G                     # Define amout of RAM, 128 gigabytes here\n#SBATCH --partition=[partition_name]   # Partition to use\n#SBATCH --gres=gpu:1                   # Generic resource specification, here a node with 1 GPU\n#SBATCH --constraint=A10               # Additional constraint: only nodes with A10 feature are valid\n#SBATCH --no-requeue                   # Do not requeue job if failed\n\n\n## Bash code to execute\nscript=\"$HOME/script.py\" # A script to be run\ndata_path=\"$HOME/some_data.txt\" # Input data\nout_path=\"$PWD\" # Path for output\n\n## Execute\nsrun /usr/bin/nvidia-smi # E.g. to validate that the node has the required GPU\nsrun python -c 'import torch; print(torch.cuda.is_available())' # To validate that Pytorch is correctly detected\nsrun python $script $data_path $out_path\nNote that lines starting with #SBATCH are SLURM directives that will be interpreted by SLRUM.\nThen, run it with the sbatch SLURM command:\nsbatch script.sh\n\n\n\nThe SLURM command to list running jobs and their status is squeue. In practice there are too many jobs and some filtering must be applied, often user-based. This can be done using standard grep with the username of interest:\nsqueue | grep [username]\nor using the specific options of squeue:\nsqueue --u [username] # or `whoami` instead of [username]\nFor more information go here.\n\n\n\nAfter running a job with sbatch SLURM will output the job ID of the running job. To cancel the job use scancel:\nscancel [jobID]\n\n\n\nDifferent jobs may have different requirements in terms of memory, cores, GPUs… In the job script we have to specify these requirements as generic resources (via --gres) or constraints (via --constraints). To list the available generic resources and features (used to specify constraints) we use sinfo:\nsinfo -o '%25N %5c %10m %40f %G'\nwhere\n\n-o is the option to specify the output format\n'%25N %5c %10m %40f %G' is the format specification:\n\nnumber after % indicates the max. length for that field\n%N to show node names\n%c to show number of cores\n%m to show available RAM memory\n%f to show available features (which can be specified in the --constraints option of a job script)\n%G to show available generic resources (used in the --gres option of a job script)\n\n\nsinfo provides lots of information about the cluster. For more information and options go here."
  },
  {
    "objectID": "notes/slurm_basic_commands.html#tldr",
    "href": "notes/slurm_basic_commands.html#tldr",
    "title": "SLURM basic commands",
    "section": "",
    "text": "Write the following SLURM directives and code in a file, e.g. job script.sh:\n#!/bin/bash\n\n#SBATCH --mail-type=ALL                # Type of events triggering email\n#SBATCH --mail-user=[email_address]    # Email address for notifications\n#SBATCH --job-name=[name_for_job]      # Job name\n#SBATCH --time=50:00:00                # Max. runtime, 50 hours in this case\n#SBATCH --mem=128G                     # Define amout of RAM, 128 gigabytes here\n#SBATCH --partition=[partition_name]   # Partition to use\n#SBATCH --gres=gpu:1                   # Generic resource specification, here a node with 1 GPU\n#SBATCH --constraint=A10               # Additional constraint: only nodes with A10 feature are valid\n#SBATCH --no-requeue                   # Do not requeue job if failed\n\n\n## Bash code to execute\nscript=\"$HOME/script.py\" # A script to be run\ndata_path=\"$HOME/some_data.txt\" # Input data\nout_path=\"$PWD\" # Path for output\n\n## Execute\nsrun /usr/bin/nvidia-smi # E.g. to validate that the node has the required GPU\nsrun python -c 'import torch; print(torch.cuda.is_available())' # To validate that Pytorch is correctly detected\nsrun python $script $data_path $out_path\nNote that lines starting with #SBATCH are SLURM directives that will be interpreted by SLRUM.\nThen, run it with the sbatch SLURM command:\nsbatch script.sh\n\n\n\nThe SLURM command to list running jobs and their status is squeue. In practice there are too many jobs and some filtering must be applied, often user-based. This can be done using standard grep with the username of interest:\nsqueue | grep [username]\nor using the specific options of squeue:\nsqueue --u [username] # or `whoami` instead of [username]\nFor more information go here.\n\n\n\nAfter running a job with sbatch SLURM will output the job ID of the running job. To cancel the job use scancel:\nscancel [jobID]\n\n\n\nDifferent jobs may have different requirements in terms of memory, cores, GPUs… In the job script we have to specify these requirements as generic resources (via --gres) or constraints (via --constraints). To list the available generic resources and features (used to specify constraints) we use sinfo:\nsinfo -o '%25N %5c %10m %40f %G'\nwhere\n\n-o is the option to specify the output format\n'%25N %5c %10m %40f %G' is the format specification:\n\nnumber after % indicates the max. length for that field\n%N to show node names\n%c to show number of cores\n%m to show available RAM memory\n%f to show available features (which can be specified in the --constraints option of a job script)\n%G to show available generic resources (used in the --gres option of a job script)\n\n\nsinfo provides lots of information about the cluster. For more information and options go here."
  },
  {
    "objectID": "notes/slurm_basic_commands.html#resources",
    "href": "notes/slurm_basic_commands.html#resources",
    "title": "SLURM basic commands",
    "section": "Resources",
    "text": "Resources\n\nOfficial SLURM documentation"
  },
  {
    "objectID": "notes/index.html",
    "href": "notes/index.html",
    "title": "Personal Notes",
    "section": "",
    "text": "Personal Notes\nThese are some notes, procedures or code snippets I find useful myself and tend to use relatively often.\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nDisk space and usage in Linux\n\n\nUsing du and df commands to collect disk…\n\n\n\n\nPytorch GPU memory management in Jupyter\n\n\nLessons learned about managing GPU memory when…\n\n\n\n\nRunning Jupyter from a remote server\n\n\nHow to run Jupyter on a remote server and access…\n\n\n\n\nSLURM basic commands\n\n\nSome basic commands to run jobs in SLURM\n\n\n\n\nSSH configuration file\n\n\nHow to configure a remote host in the SSH config…\n\n\n\n\nSSH configuration for Git repository\n\n\nHow to configure SSH access to Git repository\n\n\n\n\nSetup Jupyterlab on conda environments\n\n\nMy template to setup Jupyterlab and conda…\n\n\n\n\nShow the token of a Jupyter server\n\n\nHow to obtain the token of a running Jupyter…\n\n\n\n\nSpecify GPU device\n\n\nHow to specify GPU device\n\n\n\n\nTensorboard on a remote server\n\n\nHow to run Tensorboard on a remote server and…\n\n\n\n\nUsing find to search for recently modified files\n\n\nHow to search for recently modified files\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/ssh_keygen_and_config_for_git.html",
    "href": "notes/ssh_keygen_and_config_for_git.html",
    "title": "SSH configuration for Git repository",
    "section": "",
    "text": "Generate SSH key and add to SSH agent in the local machine:\nssh-keygen -t ed25519 -C \"sample.mail@gmail.com\" # Specify appropiate key name when prompted\neval \"$(ssh-agent -s)\"\nssh-add ~/.ssh/[key_name]\nAt this point, copy and paste the public key to your repo’s SSH key manager:\ncat ~/.ssh/[key_name].pub # Copy the output of this command and paste to key manager\nConfigure a new SSH entry in the SSH config file ~/ssh/config. Write the following:\nHost [repo_alias_hostname] # E.g. github.com, or some alias, e.g. work.github.com, if you want to manage multiple accounts\n    HostName [repo_hostname] # Repo host name\n    User [username] # User name in the repository\n    PubKeyAuthentication yes\n    IdentityFile ~/.ssh/[key_name] # Key file generated above"
  },
  {
    "objectID": "notes/ssh_keygen_and_config_for_git.html#tldr",
    "href": "notes/ssh_keygen_and_config_for_git.html#tldr",
    "title": "SSH configuration for Git repository",
    "section": "",
    "text": "Generate SSH key and add to SSH agent in the local machine:\nssh-keygen -t ed25519 -C \"sample.mail@gmail.com\" # Specify appropiate key name when prompted\neval \"$(ssh-agent -s)\"\nssh-add ~/.ssh/[key_name]\nAt this point, copy and paste the public key to your repo’s SSH key manager:\ncat ~/.ssh/[key_name].pub # Copy the output of this command and paste to key manager\nConfigure a new SSH entry in the SSH config file ~/ssh/config. Write the following:\nHost [repo_alias_hostname] # E.g. github.com, or some alias, e.g. work.github.com, if you want to manage multiple accounts\n    HostName [repo_hostname] # Repo host name\n    User [username] # User name in the repository\n    PubKeyAuthentication yes\n    IdentityFile ~/.ssh/[key_name] # Key file generated above"
  },
  {
    "objectID": "notes/ssh_keygen_and_config_for_git.html#breakdown",
    "href": "notes/ssh_keygen_and_config_for_git.html#breakdown",
    "title": "SSH configuration for Git repository",
    "section": "Breakdown",
    "text": "Breakdown\n\nThere are several algorithms to generate the SSH keys. Check the references in your Git repository’s key manager. The key generation steps can be found in any popular Git repository (Github, Gitlab…).\nThe SSH config file is not necessary but it is very useful to handle multiple Git accounts.\nIn the SSH config file, HostName can be an IP address if known, which will skip domain resolution, or a host name, which will trigger domain resolution. This may be resolved locally via /etc/hosts or require DNS queries."
  },
  {
    "objectID": "notes/ssh_keygen_and_config_for_git.html#resources",
    "href": "notes/ssh_keygen_and_config_for_git.html#resources",
    "title": "SSH configuration for Git repository",
    "section": "Resources",
    "text": "Resources\n\nOfficial Github documentation.\nStackoverflow post on how to configure SSH when working with several accounts."
  },
  {
    "objectID": "notes/setup_jupyter_on_conda_environments.html",
    "href": "notes/setup_jupyter_on_conda_environments.html",
    "title": "Setup Jupyterlab on conda environments",
    "section": "",
    "text": "In the base environment:\nconda install pip ipympl jupyterlab nb_conda_kernels jupyter_contrib_nbextensions jupyterlab_widgets\nThen, for each virtual environment that should be available in Jupyter:\nconda create -n [env_name] python==[required python version] pip\nconda activate [env_name]\nconda install ipykernel ipympl ipywidgets"
  },
  {
    "objectID": "notes/setup_jupyter_on_conda_environments.html#tldr",
    "href": "notes/setup_jupyter_on_conda_environments.html#tldr",
    "title": "Setup Jupyterlab on conda environments",
    "section": "",
    "text": "In the base environment:\nconda install pip ipympl jupyterlab nb_conda_kernels jupyter_contrib_nbextensions jupyterlab_widgets\nThen, for each virtual environment that should be available in Jupyter:\nconda create -n [env_name] python==[required python version] pip\nconda activate [env_name]\nconda install ipykernel ipympl ipywidgets"
  },
  {
    "objectID": "notes/setup_jupyter_on_conda_environments.html#breakdown",
    "href": "notes/setup_jupyter_on_conda_environments.html#breakdown",
    "title": "Setup Jupyterlab on conda environments",
    "section": "Breakdown",
    "text": "Breakdown\n\nAs an alternative, one could install a separate Jupyter instance on each virtual environment. In my experience it is tedious and error prone. For me the approach above works best.\nThe nb_conda_kernels extension enables access to individual virtual environments from the Jupyter instance installed in the base environent.\nAdding ipykernel allows the virtual environment to be accessible by Jupyter.\nJupyter is always started in the base environment. Then, each individual notebook will use one of the installed environments.\nI also install additional packages such as jupyter_contrib_extensions and jupyterlab_widgets, which I use in most of my projects."
  },
  {
    "objectID": "notes/setup_jupyter_on_conda_environments.html#resources",
    "href": "notes/setup_jupyter_on_conda_environments.html#resources",
    "title": "Setup Jupyterlab on conda environments",
    "section": "Resources",
    "text": "Resources\n\nnb_conda_kernels here\nipykernel here\nPost where I found out about this approach first"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "About Me\nHi, I’m Eder Miguel.\nI enjoy exploring computational solutions to practical problems and am always looking for opportunities to learn something new. I currently work as a Research Software Engineer at IST Austria, where I focus on developing tools for super-resolution light microscopy. This includes tasks like image and volume segmentation, stitching large microscopy datasets, and analyzing data to help biologists and neuroscientists make sense of their results.\nBefore this, I worked on physics-based simulations, particularly data-driven methods for fabric mechanics and computational design tools. Along the way, I’ve also explored topics like soft robotics, neural rendering, contact simulation, and real-time hand interaction simulations.\nI obtained my PhD in Computer Graphics in 2014. Afterwards, I was a postdoctoral researcher at IST Austria and in 2017, I co-founded Desilico Labs (now Seddi), a startup focused on fabric simulation and digitalization. In 2020, I returned to IST Austria, as a research engineer. During my time here, I took a brief break to work at Meta Zurich for a few months, before returning to my current role.\nOutside of work, I like to experiment with new ideas and side projects. This blog is a place to share some of that exploration, or simply things I find interesting.\n\n\nWhy This Blog?\nStarting this blog has been on my mind for years, but for one reason or another, it kept getting postponed.\nNow feels like the right time.\nMy goal is to share posts —whether long or short— about experiments, projects, useful resources, or ideas I find worth documenting and sharing.\n\nThanks for visiting!"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Author(s): Velicky, P., Miguel, E., Michalska, J.M. et al. Published in: Nat. Methods 20, 1256–1265 (2023). Link to publication\n\n\n\n\n\n\n Author(s): Casafranca, J. J., Cirio, G., Rodriguez, A., Miguel, E., Otaduy, M. A. Published in: Computer Graphics Forum Vol. 39(2). Link to publication\n\n\n\n\n\n\n Author(s): Malomo, L., Perez, J., Iarussi, E., Pietroni, N., Miguel, E., Cignoni, P., Bickel, B. Published in: ACM Transactions on Graphics, Vol. 37(6) (SIGGRAPH Asia 2018). Link to publication\n\n\n\n\n\n\n Author(s): Guseinov R., Miguel E., Bickel, B. Published in: ACM Transactions on Graphics, Vol. 36(4) (SIGGRAPH 2017). Link to publication\n\n\n\n\n\n\n Author(s): Miguel, E., Lepoutre, M., Bickel, B. Published in: ACM Transactions on Graphics, Vol. 35(4) (SIGGRAPH 2016). Link to publication\n\n\n\n\n\n\n Author(s): Miguel, E., Miraut, D., Otaduy, M.A. Published in: Computer Graphics Forum (Proc. of Eurographics), Volume 35, Number 2, 2016. Link to publication\n\n\n\n\n\n\n Author(s): Miguel, E., Tamstorf, R., Bradley, D., Schvartzman, S.C., Thomaszewsky, B., Bickel, B., Matusik, W., Marschner, S., Otaduy, M.A. Published in: ACM Transactions on Graphics, Vol. 32 (SIGGRAPH Asia 2013). Link to publication\n\n\n\n\n\n\n Author(s): Miguel, E., Bradley, D.,Thomaszewsky, B., Bickel, B., Matusik, W., Otaduy, M.A., Marschner, S. Published in: Computer Graphics Forum, Vol. 31 (2) (Proc. of Eurographics 2012). Link to publication"
  },
  {
    "objectID": "publications.html#journal-publications",
    "href": "publications.html#journal-publications",
    "title": "Publications",
    "section": "",
    "text": "Author(s): Velicky, P., Miguel, E., Michalska, J.M. et al. Published in: Nat. Methods 20, 1256–1265 (2023). Link to publication\n\n\n\n\n\n\n Author(s): Casafranca, J. J., Cirio, G., Rodriguez, A., Miguel, E., Otaduy, M. A. Published in: Computer Graphics Forum Vol. 39(2). Link to publication\n\n\n\n\n\n\n Author(s): Malomo, L., Perez, J., Iarussi, E., Pietroni, N., Miguel, E., Cignoni, P., Bickel, B. Published in: ACM Transactions on Graphics, Vol. 37(6) (SIGGRAPH Asia 2018). Link to publication\n\n\n\n\n\n\n Author(s): Guseinov R., Miguel E., Bickel, B. Published in: ACM Transactions on Graphics, Vol. 36(4) (SIGGRAPH 2017). Link to publication\n\n\n\n\n\n\n Author(s): Miguel, E., Lepoutre, M., Bickel, B. Published in: ACM Transactions on Graphics, Vol. 35(4) (SIGGRAPH 2016). Link to publication\n\n\n\n\n\n\n Author(s): Miguel, E., Miraut, D., Otaduy, M.A. Published in: Computer Graphics Forum (Proc. of Eurographics), Volume 35, Number 2, 2016. Link to publication\n\n\n\n\n\n\n Author(s): Miguel, E., Tamstorf, R., Bradley, D., Schvartzman, S.C., Thomaszewsky, B., Bickel, B., Matusik, W., Marschner, S., Otaduy, M.A. Published in: ACM Transactions on Graphics, Vol. 32 (SIGGRAPH Asia 2013). Link to publication\n\n\n\n\n\n\n Author(s): Miguel, E., Bradley, D.,Thomaszewsky, B., Bickel, B., Matusik, W., Otaduy, M.A., Marschner, S. Published in: Computer Graphics Forum, Vol. 31 (2) (Proc. of Eurographics 2012). Link to publication"
  },
  {
    "objectID": "publications.html#conference-publications",
    "href": "publications.html#conference-publications",
    "title": "Publications",
    "section": "Conference Publications",
    "text": "Conference Publications\n\nEfficient FEM-based simulation of soft robots modeled as kinematic chains\n Author(s): Pozzi, M., Miguel, E., Deimel, R., Malvezzi, M., Bickel, B., Brock, O., Prattichizzo, D. Published in: IEEE International Conference on Robotics and Automation 2018. Link to publication\n\n\n\n\n\nCharacterization of Nonlinear Finger Pad Mechanics for Tactile Rendering\n Author(s): Miguel, E., DAngelo, M.L., Cannella, F., Bianchi, M., Memeo, M., Bicchi, A., Caldwell, D.G., Otaduy, M.A. Published in: Proc. of World Haptics Conference, 2015. Link to publication\n\n\n\n\n\nTowards Cloth-Manipulating Characters\n Author(s): Miguel, E., Feng, A., Xu, Y. and Shapiro, A. Published in: Short paper in Computer Animation and Social Agents 2014, Houston. Link to publication\n\n\n\n\n\nEfficient Simulation of Contact Between Rigid and Deformable Objects\n Author(s): Miguel, E. and Otaduy, M.A. Published in: Proc. of Multibody Dynamics, Brussels, July 2011. Link to publication\n\n\n\n\n\nModeling and Simulation of a Human Shoulder for Interactive Medical Applications\n Author(s): Otaduy, M.A., Garre, C., Gascon, J., Miguel, E., Perez, A.G., Zurdo, J.S. Published in: Proc. of CEIG (Spanish Computer Graphics Conference), September 2010. Link to publication"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "notes/tensorboard_on_remote_server.html",
    "href": "notes/tensorboard_on_remote_server.html",
    "title": "Tensorboard on a remote server",
    "section": "",
    "text": "SSH into the remote server and run Jupyter:\nssh [user@remote]\ntensorboard --logdir [path_to_logdir] --port=[port_in_remote]\nOn the local machine, create an SSH tunnel to forward the remote port to your local machine:\nssh -NfL localhost:[port_in_local]:localhost:[port_in_remote] [user@remote]\nFinally, on your local browser, access http://localhost:[port_in_local]."
  },
  {
    "objectID": "notes/tensorboard_on_remote_server.html#tldr",
    "href": "notes/tensorboard_on_remote_server.html#tldr",
    "title": "Tensorboard on a remote server",
    "section": "",
    "text": "SSH into the remote server and run Jupyter:\nssh [user@remote]\ntensorboard --logdir [path_to_logdir] --port=[port_in_remote]\nOn the local machine, create an SSH tunnel to forward the remote port to your local machine:\nssh -NfL localhost:[port_in_local]:localhost:[port_in_remote] [user@remote]\nFinally, on your local browser, access http://localhost:[port_in_local]."
  },
  {
    "objectID": "notes/tensorboard_on_remote_server.html#breakdown",
    "href": "notes/tensorboard_on_remote_server.html#breakdown",
    "title": "Tensorboard on a remote server",
    "section": "Breakdown",
    "text": "Breakdown\n\nRun Tensorboard in the remote machine specifying the desired port where the service will be exposed.\nThe ssh command is explained in details in this other note on how to run Jupyter on a remote server."
  },
  {
    "objectID": "notes/tensorboard_on_remote_server.html#resources",
    "href": "notes/tensorboard_on_remote_server.html#resources",
    "title": "Tensorboard on a remote server",
    "section": "Resources",
    "text": "Resources\n\nStackoverflow thread with this instructions and some additional ideas and references."
  },
  {
    "objectID": "notes/get_jupyter_server_token.html",
    "href": "notes/get_jupyter_server_token.html",
    "title": "Show the token of a Jupyter server",
    "section": "",
    "text": "SSH into the remote server and run:\njupyter server list\nThis will show the list of running Jupyter servers together with the token.\nNote that it is possible to create a configuration file for Jupyter, which may overwrite certain options, e.g. specify a password instead of a token, in which case no token would be listed by the command above."
  },
  {
    "objectID": "notes/get_jupyter_server_token.html#tldr",
    "href": "notes/get_jupyter_server_token.html#tldr",
    "title": "Show the token of a Jupyter server",
    "section": "",
    "text": "SSH into the remote server and run:\njupyter server list\nThis will show the list of running Jupyter servers together with the token.\nNote that it is possible to create a configuration file for Jupyter, which may overwrite certain options, e.g. specify a password instead of a token, in which case no token would be listed by the command above."
  },
  {
    "objectID": "notes/get_jupyter_server_token.html#breakdown",
    "href": "notes/get_jupyter_server_token.html#breakdown",
    "title": "Show the token of a Jupyter server",
    "section": "Breakdown",
    "text": "Breakdown\n\njupyter can be run as a system command, followed by the specific subcommand and options.\nUse jupyter --help to obtain a detailed list of options. At the time of writing this the available subcommands are listed at the bottom of the help as Available subcommands: .....\nThe token obtained here is often requested when connecting remotely to the Jupyter server, as explained in this note."
  },
  {
    "objectID": "notes/get_jupyter_server_token.html#resources",
    "href": "notes/get_jupyter_server_token.html#resources",
    "title": "Show the token of a Jupyter server",
    "section": "Resources",
    "text": "Resources\n\nOfficial Jupyter docs"
  },
  {
    "objectID": "notes/running_jupyter_on_remote_server.html",
    "href": "notes/running_jupyter_on_remote_server.html",
    "title": "Running Jupyter from a remote server",
    "section": "",
    "text": "SSH into the remote server and run Jupyter:\nssh [user@remote]\njupyter lab --no-browser --port=[port_in_remote]\nNote that the output of the last command should include a token. We will need it when accessing the remote server from the local machine (next step).\nOn the local machine, create an SSH tunnel to forward the remote port to your local machine:\nssh -NfL localhost:[port_in_local]:localhost:[port_in_remote] [user@remote]\nFinally, on your local browser, access http://localhost:[port_in_local]. The token produced in step one may be necessary to access the Jupyter server."
  },
  {
    "objectID": "notes/running_jupyter_on_remote_server.html#tldr",
    "href": "notes/running_jupyter_on_remote_server.html#tldr",
    "title": "Running Jupyter from a remote server",
    "section": "",
    "text": "SSH into the remote server and run Jupyter:\nssh [user@remote]\njupyter lab --no-browser --port=[port_in_remote]\nNote that the output of the last command should include a token. We will need it when accessing the remote server from the local machine (next step).\nOn the local machine, create an SSH tunnel to forward the remote port to your local machine:\nssh -NfL localhost:[port_in_local]:localhost:[port_in_remote] [user@remote]\nFinally, on your local browser, access http://localhost:[port_in_local]. The token produced in step one may be necessary to access the Jupyter server."
  },
  {
    "objectID": "notes/running_jupyter_on_remote_server.html#breakdown",
    "href": "notes/running_jupyter_on_remote_server.html#breakdown",
    "title": "Running Jupyter from a remote server",
    "section": "Breakdown",
    "text": "Breakdown\n\nWe run Jupyter in the remote machine using --no-browser so that no browser is opened in the remote machine.\nAny available port can be specified to avoid port collisions.\nThe -Nf options for the SSH tunnel run the SSH session in the background (-f) without executing remote commands (-N).\nThe item localhost:[port_in_local]:localhost:[port_in_remote] can be split in two parts. The first localhost:[port_in_local] specifies the local address (the address on the local machine where the port is being opened), in this case localhost, indicating that only the local machine can access that port, and the local port, [port_in_local], where the tunnel will listen. The second localhost:[port_in_remote] indicates the address on the remote machine to connect to, here localhost, meaning that SSH will connect to a service running on the local machine, and [port_in_remote], which specifies the port in the remote machine to which the tunnel connects.\nIn order to access the remote Jupyter server, we access the local port of the SSH tunnel via http://localhost:[port_in_local]."
  },
  {
    "objectID": "notes/running_jupyter_on_remote_server.html#resources",
    "href": "notes/running_jupyter_on_remote_server.html#resources",
    "title": "Running Jupyter from a remote server",
    "section": "Resources",
    "text": "Resources\n\nStackoverflow\nFound in Hamel’s blog\nSimilar instructions found in Willem’s Fizzy Logic\nA more advanced approach using HTTPS by Davis Busteed"
  },
  {
    "objectID": "notes/set_cuda_gpu_device.html",
    "href": "notes/set_cuda_gpu_device.html",
    "title": "Specify GPU device",
    "section": "",
    "text": "A generic solution to specify the GPU device(s) to use is to set the CUDA_VISIBLE_DEVICES environment variable. When running from terminal:\nCUDA_VISIBLE_DEVICES=0,1 [executable] [params]\nWhen running inside a Jupyter notebook, use the following snippet. To avoid potential conflicts, use this before any CUDA/GPU-related modules are imported:\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
  },
  {
    "objectID": "notes/set_cuda_gpu_device.html#tldr",
    "href": "notes/set_cuda_gpu_device.html#tldr",
    "title": "Specify GPU device",
    "section": "",
    "text": "A generic solution to specify the GPU device(s) to use is to set the CUDA_VISIBLE_DEVICES environment variable. When running from terminal:\nCUDA_VISIBLE_DEVICES=0,1 [executable] [params]\nWhen running inside a Jupyter notebook, use the following snippet. To avoid potential conflicts, use this before any CUDA/GPU-related modules are imported:\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
  },
  {
    "objectID": "notes/set_cuda_gpu_device.html#breakdown",
    "href": "notes/set_cuda_gpu_device.html#breakdown",
    "title": "Specify GPU device",
    "section": "Breakdown",
    "text": "Breakdown\n\nUsing CUDA_VISIBLE_DEVICES will restrict the devices visible to the executed program. Internally, CUDA device IDs will be remmaped, i.e. cuda:0 will be mapped to the first visible device, which could could be the second one if CUDA_VISIBLE_DEVICES=1.\nCUDA_DEVICE_ORDER=PCI_BUS_ID or os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" ensures that devices are always listed according to their PCI bus ID, avoiding potential non-determinism when listing GPU devices."
  },
  {
    "objectID": "notes/set_cuda_gpu_device.html#resources",
    "href": "notes/set_cuda_gpu_device.html#resources",
    "title": "Specify GPU device",
    "section": "Resources",
    "text": "Resources\n\nPost in NVIDIA technical blog.\nStackoverflow thread specifically for Jupyter notebooks. Uses the CUDA_DEVICE_ORDER environment variable.\nPytorch documentation on torch.cuda.set_device() method (which also indicates using CUDA_VISIBLE_DEVICES is usually a better option)."
  },
  {
    "objectID": "notes/find_recently_modified_files.html",
    "href": "notes/find_recently_modified_files.html",
    "title": "Using find to search for recently modified files",
    "section": "",
    "text": "We can search for recently modified files via CLI:\nfind [path] -mtime -1 # Search for files modified 1 day or less ago\nfind [path] -mmin -60 # Search for files modified 60 minutes or less ago"
  },
  {
    "objectID": "notes/find_recently_modified_files.html#tldr",
    "href": "notes/find_recently_modified_files.html#tldr",
    "title": "Using find to search for recently modified files",
    "section": "",
    "text": "We can search for recently modified files via CLI:\nfind [path] -mtime -1 # Search for files modified 1 day or less ago\nfind [path] -mmin -60 # Search for files modified 60 minutes or less ago"
  },
  {
    "objectID": "notes/find_recently_modified_files.html#real-world-example",
    "href": "notes/find_recently_modified_files.html#real-world-example",
    "title": "Using find to search for recently modified files",
    "section": "Real-world example",
    "text": "Real-world example\nWhile using a webservice built on top of docker, it was unclear where certain files were stored. After some time trying to find the exact location through the documentation I used this approach to create a file using the webservice and then looking for any files created within the last few minutes. It turned out to be the most efficient solution, so keep it in mind!"
  },
  {
    "objectID": "notes/find_recently_modified_files.html#resources",
    "href": "notes/find_recently_modified_files.html#resources",
    "title": "Using find to search for recently modified files",
    "section": "Resources",
    "text": "Resources\n\nOfficial find man-page documentation.\nStackoverflow thread with an example."
  },
  {
    "objectID": "notes/linux_disk_space_and_usage.html",
    "href": "notes/linux_disk_space_and_usage.html",
    "title": "Disk space and usage in Linux",
    "section": "",
    "text": "To check the disk space use df (for *disk free`):\n$ df -h\nThis will list mounted drives and list the directory where they are mounted, together with the total, used and available space in human readable form.\nTo check how much space a given directory and its subdirectories or files take, use du (for disk usage):\ndu [path_to_directory] -h -d [depth]\nFor example:\n$ du . -h -d 2 -a\n\n8,0K    ./posts\n52K     ./notes\n4,0K    ./README.md\n8,0K    ./publications.qmd\n142M    .\nThis will list all (-a) directories and files in the current directory (.), and one level below (-d 2) together with the amount of disk space they take in human readable form (-h)."
  },
  {
    "objectID": "notes/linux_disk_space_and_usage.html#tldr",
    "href": "notes/linux_disk_space_and_usage.html#tldr",
    "title": "Disk space and usage in Linux",
    "section": "",
    "text": "To check the disk space use df (for *disk free`):\n$ df -h\nThis will list mounted drives and list the directory where they are mounted, together with the total, used and available space in human readable form.\nTo check how much space a given directory and its subdirectories or files take, use du (for disk usage):\ndu [path_to_directory] -h -d [depth]\nFor example:\n$ du . -h -d 2 -a\n\n8,0K    ./posts\n52K     ./notes\n4,0K    ./README.md\n8,0K    ./publications.qmd\n142M    .\nThis will list all (-a) directories and files in the current directory (.), and one level below (-d 2) together with the amount of disk space they take in human readable form (-h)."
  },
  {
    "objectID": "notes/linux_disk_space_and_usage.html#breakdown",
    "href": "notes/linux_disk_space_and_usage.html#breakdown",
    "title": "Disk space and usage in Linux",
    "section": "Breakdown",
    "text": "Breakdown\n\nAs usual with Linux commands, the built-in help is the best source of truth: du --help or df --help to obtain all available options.\nIn both commands -h is short for human-readable, which for me is a must unless the goal is to pipe the output to some other tool.\nIn the case of du another quite useful options is --time which adds the date and time the file or directory was last modified.\n\nFor example:\n$ du . -h -d 1 -a --time\n\n8,0K    2024-12-26 13:55    ./posts\n52K     2024-12-27 12:11    ./notes\n4,0K    2024-12-23 12:52    ./README.md\n8,0K    2024-12-23 12:52    ./publications.qmd\n142M    2024-12-27 12:11    ."
  },
  {
    "objectID": "notes/linux_disk_space_and_usage.html#resources",
    "href": "notes/linux_disk_space_and_usage.html#resources",
    "title": "Disk space and usage in Linux",
    "section": "Resources",
    "text": "Resources\n\ndu command explained in 101 Linux commands e-book\ndf command explained in 101 Linux commands e-book\nPost about du in redhat.com.\nPost about df in redhat.com."
  }
]